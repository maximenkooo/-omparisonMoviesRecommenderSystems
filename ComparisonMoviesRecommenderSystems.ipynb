{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# LOAD THE DATA\n",
    "#-------------------------\n",
    " \n",
    "df_movies = pd.read_csv('data/ml-20m/movies.csv')\n",
    "\n",
    "df_ratings = pd.read_csv('data/ml-20m/ratings.csv')\n",
    "\n",
    "df_tags = pd.read_csv('data/ml-20m/tags.csv')\n",
    "\n",
    "df_links = pd.read_csv('data/ml-20m/links.csv')\n",
    "\n",
    "df_genome_tags = pd.read_csv('data/ml-20m/genome-tags.csv')\n",
    "\n",
    "df_genome_scores = pd.read_csv('data/ml-20m/genome-scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a very weak computer to open all data and working with there later:с\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ratings.loc[:df_ratings.shape[0]*0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.rating != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 4)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method from the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_i = []\n",
    "for i in df.index.tolist():\n",
    "    for j in df.index.tolist():\n",
    "        list_j = []\n",
    "        if i == j: continue\n",
    "        else:\n",
    "            time_i = df.timestamp.loc[i]\n",
    "            time_j = df.timestamp.loc[j]\n",
    "            dis = time_i - time_j\n",
    "#             minutes = divmod(dis.days * 86400 + dis.seconds, 60)\n",
    "            list_j.append(dis)\n",
    "#             session[k,r] = minutes \n",
    "    list_i.append(list_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this for time in datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.timestamp = df.timestamp.astype('int').apply(\n",
    "#     lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# df.timestamp = pd.to_datetime(df.timestamp)\n",
    "\n",
    "# df.timestamp.apply(lambda x: x.day).unique()\n",
    "\n",
    "# df.timestamp.apply(lambda x: x.month).unique()\n",
    "\n",
    "# df.timestamp.apply(lambda x: x.year).unique()\n",
    "\n",
    "# ind = df_ratings.timestamp.sort_values(ascending=False).iloc[:50000].index\n",
    "\n",
    "# df_new = df.loc[ind] \n",
    "\n",
    "# df_new = df_new.dropna()h\n",
    "\n",
    "# df_new.timestamp.apply(lambda x: x.year).unique()\n",
    "\n",
    "# # # session = np.zeros([df_new.index.shape[0],df_new.index.shape[0]])\n",
    "# # k = 0\n",
    "# # r = 0\n",
    "# # list_i = []\n",
    "# # for i in df_new.index.tolist():\n",
    "# #     for j in df_new.index.tolist():\n",
    "# #         list_j = []\n",
    "# #         if i == j: continue\n",
    "# #         else:\n",
    "# #             time_i = df_new.timestamp.loc[i]\n",
    "# #             time_j = df_new.timestamp.loc[j]\n",
    "# #             dis = time_i - time_j\n",
    "# #             minutes = divmod(dis.days * 86400 + dis.seconds, 60)\n",
    "# #             list_j.append(minutes)\n",
    "# # #             session[k,r] = minutes \n",
    "# #     list_i.append(list_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1750, 3997, 4133, 7449, 5999])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.movieId.iloc[df[(df.userId == 1)].timestamp.sort_values(ascending=False)[:5].index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6743"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.userId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_session = pd.DataFrame(index=df.userId.unique(),columns=['movie%s' %i for i in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in df.userId.unique():\n",
    "    list_user = []\n",
    "    ind_ser_5 = df[(df.userId == user)].timestamp.sort_values(ascending=False)[:5].index\n",
    "    list_user = df.movieId.iloc[ind_ser_5].values\n",
    "    df_user_session.loc[user] = list_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie1</th>\n",
       "      <th>movie2</th>\n",
       "      <th>movie3</th>\n",
       "      <th>movie4</th>\n",
       "      <th>movie5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>3997</td>\n",
       "      <td>4133</td>\n",
       "      <td>7449</td>\n",
       "      <td>5999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3703</td>\n",
       "      <td>1214</td>\n",
       "      <td>260</td>\n",
       "      <td>541</td>\n",
       "      <td>1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2053</td>\n",
       "      <td>2642</td>\n",
       "      <td>2034</td>\n",
       "      <td>173</td>\n",
       "      <td>2643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>548</td>\n",
       "      <td>489</td>\n",
       "      <td>519</td>\n",
       "      <td>531</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1291</td>\n",
       "      <td>1136</td>\n",
       "      <td>1210</td>\n",
       "      <td>1198</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie1  movie2  movie3  movie4  movie5\n",
       "1    1750    3997    4133    7449    5999\n",
       "2    3703    1214     260     541    1748\n",
       "3    2053    2642    2034     173    2643\n",
       "4     548     489     519     531     596\n",
       "5    1291    1136    1210    1198    1196"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_movies():\n",
    "    return 0\n",
    "    # There should be a function of the similarity of two films.\n",
    "   # :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomend_user(user_id,df_user_session):\n",
    "    return 0\n",
    "#     here must be a circle on user session films and finding the most similar ones by simplify_movies\n",
    "#     and then ranging by function ndcg_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of all users, artists and plays\n",
    "users = list(np.sort(df.userId.unique()))\n",
    "movies = list(np.sort(df.movieId.unique()))\n",
    "ratings = list(df.rating.values)\n",
    "\n",
    "# Get the rows and columns for our new matrix\n",
    "rows = df.userId.astype(int)\n",
    "cols = df.movieId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20001 entries, 0 to 20000\n",
      "Data columns (total 4 columns):\n",
      "userId       20001 non-null int64\n",
      "movieId      20001 non-null int64\n",
      "rating       20001 non-null float64\n",
      "timestamp    20001 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 781.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "row index exceeds matrix dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-6ae33aeb1853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Contruct a sparse matrix for our users and items containing number of ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/curr_env/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;31m# (data, ij) format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/curr_env/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/curr_env/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'row index exceeds matrix dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'column index exceeds matrix dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: row index exceeds matrix dimensions"
     ]
    }
   ],
   "source": [
    "# Contruct a sparse matrix for our users and items containing number of ratings\n",
    "data_sparse = sparse.csr_matrix((ratings, (rows, cols)), shape=(len(users), len(movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 4192, 20001, 20001, 20001)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users),len(movies),len(ratings),len(rows),len(cols)#,len(plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried hard, but there was so little time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy to other data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helga/anaconda3/envs/curr_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_table('data/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv',nrows=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My computer almost died when I worked with this data. :С"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plays</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "      <td>1587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>2531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>3892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plays  user_id  artist_id\n",
       "0   1099        0       1356\n",
       "1    897        0       3135\n",
       "2    717        0       1587\n",
       "3    706        0       2531\n",
       "4    691        0       3892"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = pd.read_table('data/usersha1-artmbid-artname-plays.tsv')\n",
    "raw_data = raw_data.drop(raw_data.columns[1], axis=1)\n",
    "raw_data.columns = ['user', 'artist', 'plays']\n",
    " \n",
    "# Drop rows with missing values\n",
    "data = raw_data.dropna()\n",
    " \n",
    "# Convert artists names into numerical IDs\n",
    "data['user_id'] = data['user'].astype(\"category\").cat.codes\n",
    "data['artist_id'] = data['artist'].astype(\"category\").cat.codes\n",
    "\n",
    "# Create a lookup frame so we can get the artist names back in \n",
    "# readable form later.\n",
    "item_lookup = data[['artist_id', 'artist']].drop_duplicates()\n",
    "item_lookup['artist_id'] = item_lookup.artist_id.astype(str)\n",
    "\n",
    "data = data.drop(['user', 'artist'], axis=1)\n",
    "\n",
    "# Drop any rows that have 0 plays\n",
    "data = data.loc[data.plays != 0]\n",
    "\n",
    "# Create lists of all users, artists and plays\n",
    "users = list(np.sort(data.user_id.unique()))\n",
    "artists = list(np.sort(data.artist_id.unique()))\n",
    "plays = list(data.plays)\n",
    "\n",
    "# Get the rows and columns for our new matrix\n",
    "rows = data.user_id.astype(int)\n",
    "cols = data.artist_id.astype(int)\n",
    "\n",
    "# Contruct a sparse matrix for our users and items containing number of plays\n",
    "data_sparse = sparse.csr_matrix((plays, (rows, cols)), shape=(len(users), len(artists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 5460, 10000)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users),len(artists),len(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows),len(cols)#,len(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 20\n",
      "iteration 2 of 20\n",
      "iteration 3 of 20\n",
      "iteration 4 of 20\n",
      "iteration 5 of 20\n",
      "iteration 6 of 20\n",
      "iteration 7 of 20\n",
      "iteration 8 of 20\n",
      "iteration 9 of 20\n",
      "iteration 10 of 20\n",
      "iteration 11 of 20\n",
      "iteration 12 of 20\n",
      "iteration 13 of 20\n",
      "iteration 14 of 20\n",
      "iteration 15 of 20\n",
      "iteration 16 of 20\n",
      "iteration 17 of 20\n",
      "iteration 18 of 20\n",
      "iteration 19 of 20\n",
      "iteration 20 of 20\n"
     ]
    }
   ],
   "source": [
    "def nonzeros(m, row):\n",
    "    for index in range(m.indptr[row], m.indptr[row+1]):\n",
    "        yield m.indices[index], m.data[index]\n",
    "      \n",
    "      \n",
    "def implicit_als_cg(Cui, features=20, iterations=20, lambda_val=0.1):\n",
    "    user_size, item_size = Cui.shape\n",
    "\n",
    "    X = np.random.rand(user_size, features) * 0.01\n",
    "    Y = np.random.rand(item_size, features) * 0.01\n",
    "\n",
    "    Cui, Ciu = Cui.tocsr(), Cui.T.tocsr()\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        print( 'iteration %d of %d' % (iteration+1, iterations))\n",
    "        least_squares_cg(Cui, X, Y, lambda_val)\n",
    "        least_squares_cg(Ciu, Y, X, lambda_val)\n",
    "    \n",
    "    return sparse.csr_matrix(X), sparse.csr_matrix(Y)\n",
    "  \n",
    "def least_squares_cg(Cui, X, Y, lambda_val, cg_steps=3):\n",
    "    users, features = X.shape\n",
    "    \n",
    "    YtY = Y.T.dot(Y) + lambda_val * np.eye(features)\n",
    "\n",
    "    for u in range(users):\n",
    "\n",
    "        x = X[u]\n",
    "        r = -YtY.dot(x)\n",
    "\n",
    "        for i, confidence in nonzeros(Cui, u):\n",
    "            r += (confidence - (confidence - 1) * Y[i].dot(x)) * Y[i]\n",
    "\n",
    "        p = r.copy()\n",
    "        rsold = r.dot(r)\n",
    "\n",
    "        for it in range(cg_steps):\n",
    "            Ap = YtY.dot(p)\n",
    "            for i, confidence in nonzeros(Cui, u):\n",
    "                Ap += (confidence - 1) * Y[i].dot(p) * Y[i]\n",
    "\n",
    "            alpha = rsold / p.dot(Ap)\n",
    "            x += alpha * p\n",
    "            r -= alpha * Ap\n",
    "\n",
    "            rsnew = r.dot(r)\n",
    "            p = r + (rsnew / rsold) * p\n",
    "            rsold = rsnew\n",
    "\n",
    "        X[u] = x\n",
    "\n",
    "alpha_val = 15\n",
    "conf_data = (data_sparse * alpha_val).astype('double')\n",
    "user_vecs, item_vecs = implicit_als_cg(conf_data, iterations=20, features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIND SIMILAR ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  artist     score\n",
      "0                    !!!  0.002388\n",
      "1              girl talk  0.002068\n",
      "2                 m.i.a.  0.001862\n",
      "3           beastie boys  0.001849\n",
      "4              the knife  0.001783\n",
      "5          josé gonzález  0.001620\n",
      "6   kings of convenience  0.001591\n",
      "7              the hives  0.001574\n",
      "8  death from above 1979  0.001545\n",
      "9        lcd soundsystem  0.001540\n"
     ]
    }
   ],
   "source": [
    "item_id = 0\n",
    "\n",
    "item_vec = item_vecs[item_id].T\n",
    "\n",
    "# Calculate the similarity score and select the top 10 most similar\n",
    "scores = item_vecs.dot(item_vec).toarray().reshape(1,-1)[0]\n",
    "top_10 = np.argsort(scores)[::-1][:10]\n",
    "\n",
    "artists = []\n",
    "artist_scores = []\n",
    "\n",
    "# Get and print the actual artists names and scores\n",
    "for idx in top_10:\n",
    "    artists.append(item_lookup.artist.loc[item_lookup.artist_id == str(idx)].iloc[0])\n",
    "    artist_scores.append(scores[idx])\n",
    "\n",
    "similar = pd.DataFrame({'artist': artists, 'score': artist_scores})\n",
    "\n",
    "print( similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.02078326, -0.00892082, -0.0101311 , ...,  0.0057609 ,\n",
       "          0.00276821,  0.00745167],\n",
       "        [ 0.00065249,  0.01359133,  0.00381985, ...,  0.00756533,\n",
       "          0.00797285, -0.0044844 ],\n",
       "        [ 0.00780927,  0.00775131,  0.00090449, ..., -0.00250967,\n",
       "         -0.00097148, -0.00139671],\n",
       "        ...,\n",
       "        [ 0.00782644,  0.00776926,  0.00090653, ..., -0.0025156 ,\n",
       "         -0.00097392, -0.00139962],\n",
       "        [-0.00178266, -0.00880876,  0.01362372, ...,  0.00511504,\n",
       "          0.01726943, -0.01009385],\n",
       "        [ 0.0078399 ,  0.00778331,  0.00090814, ..., -0.00252025,\n",
       "         -0.00097583, -0.00140188]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vecs.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to recommend artists for user with ID 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out what the user has listened to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artist_id                   artist\n",
      "0       1356                die Ärzte\n",
      "1       3135        melissa etheridge\n",
      "2       1587                elvenking\n",
      "3       2531     juliette & the licks\n",
      "4       3892    red hot chili peppers\n",
      "5       2989                   magica\n",
      "6       4662  the black dahlia murder\n",
      "7       4889              the murmurs\n",
      "8       2951               lunachicks\n",
      "9       5326         walls of jericho\n",
      "10      2821           letzte instanz\n",
      "11      1978                goldfrapp\n",
      "12      2194               horrorpops\n",
      "13      4692             the butchies\n",
      "14      2322            jack off jill\n",
      "15       472         babes in toyland\n",
      "16      1480         dropkick murphys\n",
      "17       206            all:my:faults\n",
      "18      2782                 le tigre\n",
      "19      4119               schandmaul\n",
      "20      1529                    edguy\n",
      "21      3108      maximum the hormone\n",
      "22       200                 all ends\n",
      "23      2321             jack johnson\n",
      "24      1585                eluveitie\n",
      "25      3868                rasputina\n",
      "26      2887    london after midnight\n",
      "27      4841              the killers\n",
      "28      3336                  mutyumu\n",
      "29      2523             judas priest\n",
      "30      3964               rob zombie\n",
      "31      4678             the bosshoss\n",
      "32       684         blue Öyster cult\n",
      "33      4086             sandra nasic\n",
      "34      2470               john mayer\n",
      "35      4288           sleater-kinney\n",
      "36      5032                  the who\n",
      "37      1376                 disciple\n",
      "38      4558                  tanzwut\n",
      "39      2045               guano apes\n",
      "40      4945       the rolling stones\n",
      "41      2866          little big town\n",
      "42      4572              team dresch\n",
      "43       575                    betty\n",
      "44      2726                       l7\n",
      "45       583                bif naked\n",
      "46      1955               girlschool\n",
      "47      5023          the wallflowers\n"
     ]
    }
   ],
   "source": [
    "consumed_idx = data_sparse[user_id,:].nonzero()[1].astype(str)\n",
    "consumed_items = item_lookup.loc[item_lookup.artist_id.isin(consumed_idx)]\n",
    "print(consumed_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE USER RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, data_sparse, user_vecs, item_vecs, item_lookup, num_items=10):\n",
    "    \"\"\"Recommend items for a given user given a trained model\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The id of the user we want to create recommendations for.\n",
    "        \n",
    "        data_sparse (csr_matrix): Our original training data.\n",
    "        \n",
    "        user_vecs (csr_matrix): The trained user x features vectors\n",
    "        \n",
    "        item_vecs (csr_matrix): The trained item x features vectors\n",
    "        \n",
    "        item_lookup (pandas.DataFrame): Used to map artist ids to artist names\n",
    "        \n",
    "        num_items (int): How many recommendations we want to return:\n",
    "        \n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the unknowns to 1.\n",
    "    user_interactions = user_interactions.reshape(-1) + 1 #Reshape to turn into 1D array\n",
    "    user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "    rec_vector = user_vecs[user_id,:].dot(item_vecs.T).toarray()\n",
    "\n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    recommend_vector = user_interactions*rec_vector_scaled\n",
    "   \n",
    "    # Get all the artist indices in order of recommendations (descending) and\n",
    "    # select only the top \"num_items\" items. \n",
    "    item_idx = np.argsort(recommend_vector)[::-1][:num_items]\n",
    "\n",
    "    artists = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended movie indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        artists.append(item_lookup.artist.loc[item_lookup.artist_id == str(idx)].iloc[0])\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'artist': artists, 'score': scores})\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate and print our recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist     score\n",
      "0            björk  1.000000\n",
      "1       portishead  0.970637\n",
      "2        cat power  0.937699\n",
      "3        sigur rós  0.877989\n",
      "4      the beatles  0.863357\n",
      "5        [unknown]  0.863305\n",
      "6      the strokes  0.842938\n",
      "7  frédéric chopin  0.841149\n",
      "8           enigma  0.840140\n",
      "9     depeche mode  0.833239\n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend(user_id, data_sparse, user_vecs, item_vecs, item_lookup)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
